[{"title":"","date":"2022-03-25T07:50:32.000Z","path":"2022/03/25/数据库/","text":"数据库Mysql 四大特性(ACID)原子性事务必须是原子工作单元；对于其数据修改，要么全都执行，要么全都不执行。通常，与某个事务关联的操作具有共同的目标，并且是相互依赖的。如果系统只执行这些操作的一个子集，则可能会破坏事务的总体目标。原子性消除了系统处理操作子集的可能性。 一致性事务在完成时，必须使所有的数据都保持一致状态。在相关数据库中，所有规则都必须应用于事务的修改，以保持所有数据的完整性。事务结束时，所有的内部数据结构（如 B 树索引或双向链表）都必须是正确的。某些维护一致性的责任由应用程序开发人员承担，他们必须确保应用程序已强制所有已知的完整性约束。例如，当开发用于转帐的应用程序时，应避免在转帐过程中任意移动小数点。 隔离性由并发事务所作的修改必须与任何其它并发事务所作的修改隔离。事务查看数据时数据所处的状态，要么是另一并发事务修改它之前的状态，要么是另一事务修改它之后的状态，事务不会查看中间状态的数据。这称为可串行性，因为它能够重新装载起始数据，并且重播一系列事务，以使数据结束时的状态与原始事务执行的状态相同。当事务可序列化时将获得最高的隔离级别。在此级别上，从一组可并行执行的事务获得的结果与通过连续运行每个事务所获得的结果相同。由于高度隔离会限制可并行执行的事务数，所以一些应用程序降低隔离级别以换取更大的吞吐量。 持久性事务完成之后，它对于系统的影响是永久性的。该修改即使出现致命的系统故障也将一直保持。 隔离级别Read Uncommitted（读取未提交内容） 在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。 Read Committed（读取提交内容）这是大多数数据库系统的默认隔离级别（但不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别 也支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的commit，所以同一select可能返回不同结果。 Repeatable Read（可重读）这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了该问题。 Serializable（可串行化）这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。 这四种隔离级别采取不同的锁类型来实现，若读取的是同一个数据的话，就容易发生问题。例如： 脏读(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。 不可重复读(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。 幻读(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。 在MySQL中，实现了这四种隔离级别，分别有可能产生问题如下所示： 隔离级别 脏读 不可重复读 幻读 Read Uncommitted（读取未提交内容） ✔️ ✔️ ✔️ Read Committed（读取提交内容） ❌ ✔️ ✔️ Repeatable Read（可重读） ❌ ❌ ✔️ Serializable（可串行化） ❌ ❌ ❌ MVCCMVCC，全称 Multi-Version Concurrency Control ，即多版本并发控制。MVCC 是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。 地址：https://blog.csdn.net/SnailMann/article/details/94724197 什么是当前读和快照读？ 当前读像 select lock in share mode (共享锁), select for update; update; insert; delete (排他锁)这些操作都是一种当前读，为什么叫当前读？就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁 快照读像不加锁的 select 操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即 MVCC ,可以认为 MVCC 是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本 MVCC 能解决什么问题，好处是？数据库并发场景有三种，分别为： 读-读：不存在任何问题，也不需要并发控制 读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读 写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失 好处 在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能 同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题 小结MVCC + 悲观锁MVCC 解决读写冲突，悲观锁解决写写冲突MVCC + 乐观锁MVCC 解决读写冲突，乐观锁解决写写冲突 一个SQL语句的执行过程客户端-连接器-查询缓存-分析器-优化器-执行器-存储引擎 连接器长连接概念长连接是相对于短连接来说的。长连接指在一个连接上可以连续发送多个数据包，在连接保持期间，如果有数据包发送，需要双方发送链路检测包。mysql的长连接如果长期闲置，mysql会8小时后自动断开该连接。 短连接概念是指双方有数据交互时，就建立一个连接，数据发送完成后，则断开此连接，即每次连接只完成一项业务的发送。 短连接 VS 长连接 建立连接的过程是复杂的，在使用中尽量减少建立连接的操作，尽量使用长连接。 如果全部使用长连接，会导致Mysql内存涨的特别快，导致内存占用大，被系统强行杀掉了。 如何解决长连接 定期断开长连接 执行一个比较大的操作后，通过执行mysql_reset_connection来初始化连接资源。这个过程不需要重新连接和权限验证。（mysql 5.7以上的版本） 查询缓存查询缓存是什么SQL文本与查询结果的映射 缓存条件 查询SQL语句完全相同（空格和大小写严格校验） 开启查询缓存 query_cache_type 0 不使用查询缓存 1 始终使用查询缓存 2 按需使用查询缓存 1.query_cache_type值为1时，不想使用缓存中查询的数据 SELECT SQL_NO_CACHE * FROM my_table WHERE condition; 2.query_cache_type值为2，要使用缓存的话，需要使用SQL_CACHE开关参数： SELECT SQL_CACHE * FROM my_table WHERE condition; 缓存失效时机在表结构或者数据发生改变时，查询的数据不再有效。（INSERT、UPDATE、DELETE、ALERT等）Mysql8.0版本将查询缓存的整个模块删除。\u0010 解析器分为词法分析和语法分析词法分析采用Lex词法分析器LexLex是Unix环境下非常著名的工具,主要功能是生成一个词法分析器(scanner)的C源码，描述规则采用正则表达式。 语法分析采用 yacc是一个典型的语法解析器。yacc生成的编译器主要是用C语言写成的语法解析器（Parser），需要与词法解析器Lex一起使用，再把两部份产生出来的C程序一并编译。 select id, name from table1 where id=1 语句被解析为 sql_command = SQLCOM_SELECT where子句 :select_lex-&gt;where table列表：select_lex-&gt;table_list 字段列表：select_lex-&gt;item_list table_list 保存表名 wherewhere |–&gt;FUNC_ITEM |--&gt;FIELD_ITEM(&quot;id&quot;) |--&gt;INT_ITEM(1) item_list item_list: |–&gt;Item_field(“id”) |–&gt;Item_field(“name”) 优化器优化步骤 根据语法树及统计统计，构建初始表访问数组（init_plan_arrays） 根据表访问数组，计算每个表的最佳访问路径(find_best_ref)，同时保存当前最优执行计划（COST最小） 如果找到更优的执行计划则更新最优执行计划，否则优化结束。 举例select * from table1 join table2 using（id） where table1.c = 10 and table2.d = 20; 两种方案 从表1里面取出c=10的记录的ID值，再根据ID值关联到t2，再判断t2里面的d值是否等于20。 也可以先从表2中取出记录d=20的ID值，再根据ID值关联到t1，在判断t1的c值是否等于10。 InnoDB与MyISAM区别地址：https://blog.csdn.net/qq_45076180/article/details/115111803 MyISAM存储引擎MyISAM无论是主键索引还是非主键索引都是非聚集索引（叶子节点不包含所有数据记录）,索引文件和数据文件是分离的，跨文件查询速度比较慢。 InnoDB存储引擎InnoDB的主键索引就是聚集索引（叶子节点包含了完整的数据记录，查询速度较快），聚集索引在innoDB表中只有一个。 InnoDB的非主键索引就是非聚集索引（叶子节点存储的是主键的id，用于回表查询，回表查询导致速度较慢）非主键索引包括 二级索引、复合索引 等等 InnoDB与MyISAM的区别 InnoDB 支持事务，MyISAM 不支持。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一 InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限 InnoDB 是聚集索引，MyISAM 是非聚集索引 InnoDB 支持外键， MyISAM 不支持 InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快 聚簇索引和非聚簇索引 非聚簇索引 Myisam 索引与数据的关系 Myisam 索引指向行所在磁盘的位置 数据都有自己的地址 数据和索引相互独立 聚簇索引 主键索引 既存索引值，又在叶子中存储行的数据 如果没有主键（primary key），则会Unique key做主键 如果没有unique，则系统生成一个内部的rowid做主键 像innodb中，主键的索引结构中既存储了主键值，又存储了行数据的这样的结构c称为“聚簇索引” 聚簇索引和非聚簇索引的优缺点 优势：根据主键查询条目比较少，不用回行(数据就在主键节点下) 劣势: 如果碰到不规则数据插入时会造成频繁的页分裂。####索引覆盖索引覆盖是指查询的列恰好是索引的一部分，那么查询只需要在索引文件上进行，不需要回行到磁盘在查找数据，这样查询速度非常快 理想的索引 查询频繁 区分度高 长度小 尽可能覆盖常用字段 Mysql建表、列选择注意点建表原则 定长与变长相分离 常用字段和不常用字段要分离 1对多，需要关联统计的字段上，添加冗余字段(空间和时间上的转换) 列选择原则 字段类型优先级 整形 &gt; date,time &gt; enum,char &gt; varchar &gt; blob,text time 定长,运算快，节省空间,考虑时区，写sql时不方便 where &gt; ‘2005-10-12’;enum 能起到约束值的目的，内部用整形来存储char 定长 需要考虑字符集和(排序校对集)varchar 不定长 要考虑字符集的转换与排序时校对集，速度慢text/Blob 无法使用内存临时表（排序等操作只能在磁盘上进行） 够用就行，不要慷慨 原因：大的字段浪费内存，影响速度以年龄为例，tinyint unsigned not null 可以存储255岁,足够使用 ,用int浪费了3个字节以varchar(10) 和 varchar(300) 存储的内容相同，但是在表的联查上varchar(300)要花费更多的内存。 尽量避免使用NULL 原因：NULL 不利于索引 要用特殊字节来标注","tags":[]},{"title":"","date":"2022-03-08T10:47:20.000Z","path":"2022/03/08/Go/","text":"GoGo协程简单用法对于IO密集型计算可以采用go协程进行处理，使用这三个协程的操作，同时处理可以有效降低耗时。 go学习之- cas的理解https://blog.csdn.net/chenxun_2010/article/details/103598252 make和new的区别 new 和 make 都用于分配内存； new 和 make 都是在堆上分配内存； new 对指针类型分配内存，返回值是分配类型的指针，new不能直接对 slice 、map、channel 分配内存； make 仅用于 slice、map和 channel 的初始化，返回值为类型本身，而不是指针； ####","tags":[]},{"title":"","date":"2022-03-06T03:57:42.000Z","path":"2022/03/06/架构/","text":"架构分布式系统CAP理论概念一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项 定义Consistency 一致性 一致性是因为多个数据拷贝下并发读写才有的问题，因此理解时一定要注意结合考虑多个数据拷贝下并发读写的场景。 Availability 可用性可用性指“Reads and writes always succeed”，即服务在正常响应时间内一直可用。好的可用性主要是指系统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况。可用性通常情况下可用性和分布式数据冗余，负载均衡等有着很大的关联。 Partition Tolerance分区容错性分区容错性指“the system continues to operate despite arbitrary message loss or failure of part of the system”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性或可用性的服务。 CAP权衡 CA without P：如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但其实分区不是你想不想的问题，而是始终会存在，因此CA的系统更多的是允许分区后各子系统依然保持CA。 CP without A：如果不要求A（可用），相当于每个请求都需要在Server之间强一致，而P（分区）会导致同步时间无限延长，如此CP也是可以保证的。很多传统的数据库分布式事务都属于这种模式。 AP wihtout C：要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。现在众多的NoSQL都属于此类。 Raft算法详解Raft算法概述将一致性分解为多个子问题：Leader选举（Leader election）、日志同步（Log replication）、安全性（Safety）、日志压缩（Log compaction）、成员变更（Membership change。Raft将系统中的角色分为领导者（Leader）、跟从者（Follower）和候选人（Candidate）： Leader：接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。Follower：接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。Candidate：Leader选举过程中的临时角色。 Raft要求系统在任意时刻最多只有一个Leader，正常工作期间只有Leader和Followers。 Raft算法角色状态转换如下 Leader选举Raft 使用心跳（heartbeat）触发Leader选举。当服务器启动时，初始化为Follower。Leader向所有Followers周期性发送heartbeat。如果Follower在选举超时时间内没有收到Leader的heartbeat，就会等待一段随机的时间后发起一次Leader选举。Follower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC （RPC细节参见八、Raft算法总结）。结果有以下三种情况： 赢得了多数的选票，成功选举为Leader； 收到了Leader的消息，表示有其它服务器已经抢先当选了Leader； 没有服务器赢得多数的选票，Leader选举失败，等待选举时间超时后发起下一次选举。 日志同步Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目（Log entries）加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC （RPC细节参见八、Raft算法总结）复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。 某些Followers可能没有成功的复制日志，Leader会无限的重试 AppendEntries RPC直到所有的Followers最终存储了所有的日志条目。 日志由有序编号（log index）的日志条目组成。每个日志条目包含它被创建时的任期号（term），和用于状态机执行的命令。如果一个日志条目被复制到大多数服务器上，就被认为可以提交（commit）了。 分布式锁基于Redis的实现方式1、选用Redis实现分布式锁原因： Redis有很高的性能； Redis命令对此支持较好，实现起来比较方便 2、使用命令介绍： SETNX EXPIRE DELETE在使用Redis实现分布式锁的时候，主要就会使用到这三个命令。 3、实现思想： 获取锁的时候，使用setnx加锁，并使用expire命令为锁添加一个超时时间，超过该时间则自动释放锁，锁的value值为一个随机生成的UUID，通过此在释放锁的时候进行判断。 获取锁的时候还设置一个获取的超时时间，若超过这个时间则放弃获取锁。 释放锁的时候，通过UUID判断是不是该锁，若是该锁，则执行delete进行锁释放 基于数据库的实现方式基于数据库的实现方式的核心思想是：在数据库中创建一个表，表中包含方法名等字段，并在方法名字段上创建唯一索引，想要执行某个方法，就使用这个方法名向表中插入数据，成功插入则获取锁，执行完成后删除对应的行数据释放锁。使用基于数据库的这种实现方式很简单，但是对于分布式锁应该具备的条件来说，它有一些问题需要解决及优化： 因为是基于数据库实现的，数据库的可用性和性能将直接影响分布式锁的可用性及性能，所以，数据库需要双机部署、数据同步、主备切换； 不具备可重入的特性，因为同一个线程在释放锁之前，行数据一直存在，无法再次成功插入数据，所以，需要在表中新增一列，用于记录当前获取到锁的机器和线程信息，在再次获取锁的时候，先查询表中机器和线程信息是否和当前机器和线程相同，若相同则直接获取锁； 没有锁失效机制，因为有可能出现成功插入数据后，服务器宕机了，对应的数据没有被删除，当服务恢复后一直获取不到锁，所以，需要在表中新增一列，用于记录失效时间，并且需要有定时任务清除这些失效的数据； 不具备阻塞锁特性，获取不到锁直接返回失败，所以需要优化获取逻辑，循环多次去获取。 在实施的过程中会遇到各种不同的问题，为了解决这些问题，实现方式将会越来越复杂；依赖数据库需要一定的资源开销，性能问题需要考虑。 基于ZooKeeper的实现方式ZooKeeper是一个为分布式应用提供一致性服务的开源组件，它内部是一个分层的文件系统目录树结构，规定同一个目录下只能有一个唯一文件名。基于ZooKeeper实现分布式锁的步骤如下： 创建一个目录mylock； 线程A想获取锁就在mylock目录下创建临时顺序节点； 获取mylock目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁； 线程B获取所有节点，判断自己不是最小节点，设置监听比自己次小的节点； 线程A处理完，删除自己的节点，线程B监听到变更事件，判断自己是不是最小的节点，如果是则获得锁。 优点：具备高可用、可重入、阻塞锁特性，可解决失效死锁问题。缺点：因为需要频繁的创建和删除节点，性能上不如Redis方式。 高并发下接口幂等性解决方案概念在编程中.一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，“getUsername()和setTrue()”函数就是一个幂等函数. 更复杂的操作幂等保证是利用唯一交易号(流水号)实现. 幂等性场景 查询操作：查询一次和查询多次，在数据不变的情况下，查询结果是一样的。select是天然的幂等操作； 删除操作：删除操作也是幂等的，删除一次和多次删除都是把数据删除。(注意可能返回结果不一样，删除的数据不存在，返回0，删除的数据多条，返回结果多个) ； 唯一索引：防止新增脏数据。比如：支付宝的资金账户，支付宝也有用户账户，每个用户只能有一个资金账户，怎么防止给用户创建资金账户多个，那么给资金账户表中的用户ID加唯一索引，所以一个用户新增成功一个资金账户记录。要点：唯一索引或唯一组合索引来防止新增数据存在脏数据（当表存在唯一索引，并发时新增报错时，再查询一次就可以了，数据应该已经存在了，返回结果即可）； token机制：防止页面重复提交。 原理上通过session token来实现的(也可以通过redis来实现)。当客户端请求页面时，服务器会生成一个随机数Token，并且将Token放置到session当中，然后将Token发给客户端（一般通过构造hidden表单）。 下次客户端提交请求时，Token会随着表单一起提交到服务器端。 服务器端第一次验证相同过后，会将session中的Token值更新下，若用户重复提交，第二次的验证判断将失败，因为用户提交的表单中的Token没变，但服务器端session中Token已经改变了。 悲观锁 获取数据的时候加锁获取。select * from table_xxx where id=’xxx’ for update; 注意：id字段一定是主键或者唯一索引，不然是锁表，会死人的；悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，根据实际情况选用； 乐观锁——乐观锁只是在更新数据那一刻锁表，其他时间不锁表，所以相对于悲观锁，效率更高。乐观锁的实现方式多种多样可以通过version或者其他状态条件： 通过版本号实现update table_xxx set name=#name#,version=version+1 where version=#version#如下图(来自网上)； 通过条件限制 update table_xxx set avai_amount=avai_amount-#subAmount# where avai_amount-#subAmount# &gt;= 0要求：quality-#subQuality# &gt;= ，这个情景适合不用版本号，只更新是做数据安全校验，适合库存模型，扣份额和回滚份额，性能更高； 分布式锁 如果是分布是系统，构建全局唯一索引比较困难，例如唯一性的字段没法确定，这时候可以引入分布式锁，通过第三方的系统(redis或zookeeper)，在业务系统插入数据或者更新数据，获取分布式锁，然后做操作，之后释放锁，这样其实是把多线程并发的锁的思路，引入多多个系统，也就是分布式系统中得解决思路。要点：某个长流程处理过程要求不能并发执行，可以在流程执行之前根据某个标志(用户ID+后缀等)获取分布式锁，其他流程执行时获取锁就会失败，也就是同一时间该流程只能有一个能执行成功，执行完成后，释放分布式锁(分布式锁要第三方系统提供)； select + insert 并发不高的后台系统，或者一些任务JOB，为了支持幂等，支持重复执行，简单的处理方法是，先查询下一些关键数据，判断是否已经执行过，在进行业务处理，就可以了。注意：核心高并发流程不要用这种方法； 状态机幂等 在设计单据相关的业务，或者是任务相关的业务，肯定会涉及到状态机(状态变更图)，就是业务单据上面有个状态，状态在不同的情况下会发生变更，一般情况下存在有限状态机，这时候，如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等。注意：订单等单据类业务，存在很长的状态流转，一定要深刻理解状态机，对业务系统设计能力提高有很大帮助 对外提供接口的api如何保证幂等 如银联提供的付款接口：需要接入商户提交付款请求时附带：source来源，seq序列号；source+seq在数据库里面做唯一索引，防止多次付款(并发时，只能处理一个请求) 。 重点：对外提供接口为了支持幂等调用，接口有两个字段必须传，一个是来源source，一个是来源方序列号seq，这个两个字段在提供方系统里面做联合唯一索引，这样当第三方调用时，先在本方系统里面查询一下，是否已经处理过，返回相应处理结果；没有处理过，进行相应处理，返回结果。注意，为了幂等友好，一定要先查询一下，是否处理过该笔业务，不查询直接插入业务系统，会报错，但实际已经处理了。","tags":[]},{"title":"","date":"2022-03-06T03:16:48.000Z","path":"2022/03/06/Redis/","text":"Redis缓存穿透、缓存击穿、缓存雪崩缓存穿透描述： 缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求。由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。 在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。 如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。解决方案接口层增加校验，如用户鉴权校验，id做基础校验，id&lt;=0的直接拦截；从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击 缓存击穿描述： 缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。 解决方案 设置热点数据永远不过期。 接口限流与熔断，降级。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些 服务 不可用时候，进行熔断，失败快速返回机制。 布隆过滤器。bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小， 加互斥锁 缓存雪崩描述： 缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是， 缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。 解决方案： 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。 设置热点数据永远不过期。 Redis中connect与pconnect区别？1.首先先介绍下connect和pconnect的区别。connect：脚本结束之后连接就释放了。 2.pconnect：脚本结束之后连接不释放，连接保持在php-fpm进程中。所以使用pconnect代替connect，可以减少频繁建立redis连接的消耗。","tags":[]},{"title":"","date":"2022-03-06T02:45:56.000Z","path":"2022/03/06/网络基础/","text":"网络基础TCPTCP滑动窗口滑动窗口tcp通过滑动窗口进行流量控制，所谓的窗口可以理解为接收端所能提供的缓冲区大小。 TCP是一个滑动窗口协议，即一个TCP连接的发送端在某个时刻能发多少数据是由滑动窗口控制的 滑动窗口示意图 RTT（Round trip time）表示从发送端到接收端的一去一回需要的时间。 TCP在数据传输过程中会对RTT进行采样（即对发送的数据包及其ACK的时间差进行测量，并根据测量值更新RTT值） RTO （Retransmission TimeOut）发送数据包，启动重传定时器，重传定时器到期所花费的时间 TCP根据得到的RTT值更新RTO值，即Retransmission TimeOut，就是重传间隔，发送端对每个发出的数据包进行计时，如果在RTO时间内没有收到所发出的数据包的对应ACK，则任务数据包丢失，将重传数据。一般RTO值都比采样得到的RTT值要大。 在面对未知的流量暴增，可以预先怎么处理 大致为以下两种情况 1. 不可预测流量（网站被恶意刷量；CDN回源抓取数据；合作业务平台调取平台数据等） 2. 可预测流量（突然爆发的社会热点，营销活动的宣传；） 防止流量暴涨的预备方案 通过压测，进行流量预估，流量基本上要在压测结果，压测得到的结果要达到设计流量 3（4， * 5都可以） 降级方案，需要考虑业务场景，采用不同的降级方案，不能随意在业务主流程进行 限流方案：计数器、滑动窗口、漏桶 计数器 计数器是一种比较简单的限流算法，用途比较广泛，在接口层面，很多地方使用这种方式限流。在一段时间内，进行计数，与阀值进行比较，到了时间临界点，将计数器清0。局限性：这里需要注意的是，存在一个时间临界点的问题。举个栗子，在12:01:00到12:01:58这段时间内没有用户请求，然后在12:01:59这一瞬时发出100个请求，OK，然后在12:02:00这一瞬时又发出了100个请求。这里你应该能感受到，在这个临界点可能会承受恶意用户的大量请求，甚至超出系统预期的承受。 滑动窗口 由于计数器存在临界点缺陷，后来出现了滑动窗口算法来解决 局限性：滑动窗口的意思是说把固定时间片，进行划分，并且随着时间的流逝，进行移动，这样就巧妙的避开了计数器的临界点问题。也就是说这些固定数量的可以移动的格子，将会进行计数判断阀值，因此格子的数量影响着滑动窗口算法的精度 漏桶 虽然滑动窗口有效避免了时间临界点的问题，但是依然有时间片的概念，而漏桶算法在这方面比滑动窗口而言，更加先进。有一个固定的桶，进水的速率是不确定的，但是出水的速率是恒定的，当水满的时候是会溢出的。 局限性： 生成令牌的速度是恒定的，而请求去拿令牌是没有速度限制的。这意味，面对瞬时大流量，该算法可以在短时间内请求拿到大量令牌，而且拿令牌的过程并不是消耗很大的事情。（有一点生产令牌，消费令牌的意味）不论是对于令牌桶拿不到令牌被拒绝，还是漏桶的水满了溢出，都是为了保证大部分流量的正常使用，而牺牲掉了少部分流量，这是合理的，如果因为极少部分流量需要保证的话，那么就可能导致系统达到极限而挂掉，得不偿失。 浏览器访问 www.baidu.com 的过程 浏览器向DNS服务器发出解析域名的请求； DNS服务器将”www.baidu.com”域名解析为对应的IP地址，并返回给浏览器； 浏览器与百度服务器进行三次握手，建立TCP连接； 浏览器发出HTTP请求报文； 服务器回复HTTP响应报文； 浏览器解析响应报文，渲染HTML内容，并显示在页面上； 收发报文结束，释放TCP连接，执行四次挥手。 TCP三次握手 建立连接在TCP/IP协议中,TCP协议提供可靠的连接服务,采用三次握手建立一个连接. 第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。 SYN：同步序列编号(Synchronize Sequence Numbers) 第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。 第三次握手：Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。 TCP四次挥手1.第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。 2.第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。 3.第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。 4.第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1， Server进入CLOSED状态，完成四次挥手。 IO 多路复用同步阻塞select，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 Select、Poll与Epoll区别 \\ select poll epoll 支持最大连接数 1024（x86） or 2048（x64） 无上限 无上限 IO效率 每次调用进行线性遍历，时间复杂度为O（N） 每次调用进行线性遍历，时间复杂度为O（N） 使用“事件”通知方式，每当fd就绪，系统注册的回调函数就会被调用，将就绪fd放到rdllist里面，这样epoll_wait返回的时候我们就拿到了就绪的fd。时间发复杂度O（1） fd拷贝 每次select都拷贝 每次poll都拷贝 调用epoll_ctl时拷贝进内核并由内核保存，之后每次epoll_wait不拷贝 Linux IO模型网络IO的本质是socket的读取，socket在linux系统被抽象为流，IO可以理解为对流的操作。常见的IO模型有阻塞、非阻塞、IO多路复用，异步 同步阻塞IO同步阻塞 IO 模型是最常用的一个模型，也是最简单的模型。在linux中，默认情况下所有的socket都是blocking。它符合人们最常见的思考逻辑。阻塞就是进程 “被” 休息, CPU处理其它进程去了。 同步非堵塞IO同步非阻塞就是 “每隔一会儿瞄一眼进度条” 的轮询（polling）方式。 对比同步阻塞IO优点：能够在等待任务完成的时间里干其他活了（包括提交其他任务，也就是 “后台” 可以有多个任务在同时执行）。缺点：任务完成的响应延迟增大了，因为每过一段时间才去轮询一次read操作，而任务可能在两次轮询之间的任意时间完成。这会导致整体数据吞吐量的降低。 进程一个在内存中运行的应用程序。每个进程都有自己独立的一块内存空间，一个进程可以有多个线程，比如在Windows系统中，一个运行的xx.exe就是一个进程。 线程进程中的一个执行任务（控制单元），负责当前进程中程序的执行。一个进程至少有一个线程，一个进程可以运行多个线程，多个线程可共享数据。 与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。 进程与线程的区别总结线程具有许多传统进程所具有的特征，故又称为轻型进程(Light—Weight Process)或进程元；而把传统的进程称为重型进程(Heavy—Weight Process)，它相当于只有一个线程的任务。在引入了线程的操作系统中，通常一个进程都有若干个线程，至少包含一个线程。 根本区别：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位 资源开销：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。 包含关系：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。 内存分配：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的 影响关系：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。 执行过程：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行 CPU密集型和IO密集型CPU密集型CPU密集型也叫计算密集型，指的是系统的硬盘、内存性能相对CPU要好很多，此时，系统运作CPU读写IO(硬盘/内存)时，IO可以在很短的时间内完成，而CPU还有许多运算要处理，因此，CPU负载很高。 CPU密集表示该任务需要大量的运算，而没有阻塞，CPU一直全速运行。CPU密集任务只有在真正的多核CPU上才可能得到加速（通过多线程），而在单核CPU上，无论你开几个模拟的多线程该任务都不可能得到加速，因为CPU总的运算能力就只有这么多。 CPU使用率较高（例如:计算圆周率、对视频进行高清解码、矩阵运算等情况）的情况下，通常，线程数只需要设置为CPU核心数的线程个数就可以了。 这一情况多出现在一些业务复杂的计算和逻辑处理过程中。比如说，现在的一些机器学习和深度学习的模型训练和推理任务，包含了大量的矩阵运算。 IO密集型IO密集型指的是系统的CPU性能相对硬盘、内存要好很多，此时，系统运作，大部分的状况是CPU在等IO (硬盘/内存) 的读写操作，因此，CPU负载并不高。 密集型的程序一般在达到性能极限时，CPU占用率仍然较低。这可能是因为任务本身需要大量I/O操作，而程序的逻辑做得不是很好，没有充分利用处理器能力。 CPU 使用率较低，程序中会存在大量的 I/O 操作占用时间，导致线程空余时间很多，通常就需要开CPU核心数数倍的线程。 其计算公式为：IO密集型核心线程数 = CPU核数 / （1-阻塞系数）。 当线程进行 I/O 操作 CPU 空闲时，启用其他线程继续使用 CPU，以提高 CPU 的使用率。例如：数据库交互，文件上传下载，网络传输等。 CPU密集型与IO密集型任务的使用说明当线程等待时间所占比例越高，需要越多线程，启用其他线程继续使用CPU，以此提高CPU的利用率；当线程CPU时间所占比例越高，需要越少的线程，通常线程数和CPU核数一致即可，这一类型在开发中主要出现在一些计算业务频繁的逻辑中。 CPU密集型任务与IO密集型任务的区别计算密集型任务的特点是要进行大量的计算，消耗CPU资源，全靠CPU的运算能力。这种计算密集型任务虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数，避免线程或进程的切换。 计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用C语言编写。IO密集型任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。涉及到网络、磁盘IO的任务都是IO密集型任务， 对于IO密集型任务，线程数越多，CPU效率越高，但也有一个限度。 总结一个计算为主的应用程序（CPU密集型程序），多线程或多进程跑的时候，可以充分利用起所有的 CPU 核心数，比如说16核的CPU ，开16个线程的时候，可以同时跑16个线程的运算任务，此时是最大效率。但是如果线程数/进程数远远超出 CPU 核心数量，反而会使得任务效率下降，因为频繁的切换线程或进程也是要消耗时间的。因此对于 CPU 密集型的任务来说，线程数/进程数等于 CPU 数是最好的了。如果是一个磁盘或网络为主的应用程序（IO密集型程序），一个线程处在 IO 等待的时候，另一个线程还可以在 CPU 里面跑，有时候 CPU 闲着没事干，所有的线程都在等着 IO，这时候他们就是同时的了，而单线程的话，此时还是在一个一个等待的。我们都知道IO的速度比 https原理HTTP与HTTPS有什么区别？HTTPS和HTTP的区别主要如下： https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。 http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。 http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。 非对称加密方案 某网站服务器拥有公钥A与对应的私钥A’；浏览器拥有公钥B与对应的私钥B’。 浏览器把公钥B明文传输给服务器。 服务器把公钥A明文给传输浏览器。 之后浏览器向服务器传输的内容都用公钥A加密，服务器收到后用私钥A’解密。由于只有服务器拥有私钥A’，所以能保证这条数据的安全。 同理，服务器向浏览器传输的内容都用公钥B加密，浏览器收到后用私钥B’解密。同上也可以保证这条数据的安全。 数字签名数字签名的制作过程： CA机构拥有非对称加密的私钥和公钥。 CA机构对证书明文数据T进行hash。 对hash后的值用私钥加密，得到数字签名S。 浏览器验证过程： 拿到证书，得到明文T，签名S。 用CA机构的公钥对S解密（由于是浏览器信任的机构，所以浏览器保有它的公钥。详情见下文），得到S’。 用证书里指明的hash算法对明文T进行hash得到T’。 显然通过以上步骤，T’应当等于S‘，除非明文或签名被篡改。所以此时比较S’是否等于T’，等于则表明证书可信。 制作数字签名时需要hash一次？最显然的是性能问题，前面我们已经说了非对称加密效率较差，证书信息一般较长，比较耗时。而hash后得到的是固定长度的信息（比如用md5算法hash后可以得到固定的128位的值），这样加解密就快很多。 每次进行HTTPS请求时都必须在SSL/TLS层（http的安全层）进行握手传输密钥吗？服务器会为每个浏览器（或客户端软件）维护一个session ID，在TLS握手阶段传给浏览器，浏览器生成好密钥传给服务器后，服务器会把该密钥存到相应的session ID下，之后浏览器每次请求都会携带session ID，服务器会根据session ID找到相应的密钥并进行解密加密操作，这样就不必要每次重新制作、传输密钥了！ Linux根据文件路径查找索引节点查找时，会遍历路径的过程中，会逐层地将各个路径组成部分解析成目录项对象。如果此目录项对象在目录项缓存中，则直接从缓存中获取；如果该目录项在缓存中不存在，则进行一次实际的读盘操作，从磁盘中读取该目录项所对应的索引节点。得到索引节点之后，则建立索引节点与该目录项的联系。如此循环，直到找到目标文件对于的目录项，也就找到了索引节点，而由索引节点找到对应的超级块对象，就可知道该文件所在的文件系统的类型。 进程创建时文件的复制与共享当一个进程系统调用fork()创建一个子进程时，fork()将调用内核函数do_fork()对父进程的进程控制块进行复制，并将这个副本作为子进程的控制块。如果父进程有已经打开的文件，那么子进程理所当然的按某种方式来继承这些文件","tags":[]},{"title":"","date":"2022-03-01T05:24:34.000Z","path":"2022/03/01/算法/","text":"算法树二叉树L、D、R分别表示遍历左子树、访问根结点和遍历右子树 先序遍历：DLR 中序遍历：LDR 后序遍历：LRD 仅有前序和后序遍历，不能确定一个二叉树，必须有中序遍历的结果 二叉树的性质 性质1：在二叉树中第 i 层的结点数最多为 2^i-1 （i ≥ 1） 性质2：高度为k的二叉树其结点总数最多为 2^k －1 （k ≥ 1） 性质3：对任意的非空二叉树 T ，如果叶结点的个数为n0，而其度为 2 的结点数为 n2，则： n0 = n2 + 1 满二叉树深度为k，且有 2^k -1 个节点称之为 满二叉树； 性质4：第i层上的节点数为 2^i -1 ； 完全二叉树深度为k，有n个节点的二叉树，当且仅当其每一个节点都与深度为k的满二叉树中，序号为1至n的节点对应时，称之为完全二叉树。 性质5：对于具有n个结点的完全二叉树的高度为 log2^n +1： 平衡二叉树B-Tree红黑树每个节点上只存一个数据，导致大数据量时高度太高，B-Tree为了优化数的高度，如图所示：每一层树高上存储多个节点，节点中的数据索引从左到右递增排列，这样每个节点区间（数据页）内又可以向下延伸新的节点区间（数据页）。这样每一层都可以放更多的索引元素，有效的降低了树的高度，B-Tree具有以下特点： 节点中的数据索引从左到右递增排列 所有索引节点上都存储数据，所有索引节点不重复 B+Tree B+Tree 作为 B-Tree的变种，有以下特点 非叶子节点不存储data，只存储索引(冗余)，可以放更多的索引 叶子节点包含所有索引字段 节点中的数据索引从左到右递增排列，叶子节点用指针连接，提高区间访问的性能 B+Tree在查询数据时，也是从上往下查询的，首先第一次磁盘IO把B+Tree的第一层数据加载到内存中，然后通过算法找到找个要查的这个数据位于第一层的哪个区间（数据页），然后再进行一次磁盘IO把这个区间加载到内存，到这个区间中去找，以此类推。。。最终可找到想要的数据！mysql正是使用了B+Tree的数据结构，才可以支撑千万级的数据。 二叉树（先序、中序、后序遍历）package main import &quot;fmt&quot; type Tree struct { No int Left *Tree Right *Tree } func PreTree(node *Tree) { if node != nil { fmt.Printf(&quot;no:%d \\n&quot;, node.No) PreTree(node.Left) PreTree(node.Right) } } func InfixTree(node *Tree) { if node != nil { InfixTree(node.Left) fmt.Printf(&quot;no:%d \\n&quot;, node.No) InfixTree(node.Right) } } func AfterTree(node *Tree) { if node != nil { AfterTree(node.Left) AfterTree(node.Right) fmt.Printf(&quot;no:%d \\n&quot;, node.No) } } func buildTree(nums []int, l int, r int) *Tree { if l &gt; r { return nil } mid := (l + r) &gt;&gt; 1 node := &amp;Tree{nums[mid], nil, nil} node.Left = buildTree(nums, l, mid-1) node.Right = buildTree(nums, mid+1, r) return node } func main() { nums := []int{1, 2, 3} root := buildTree(nums, 0, len(nums)-1) fmt.Print(root.Left.No) fmt.Print(root.Right.No) //PreTree(root) AfterTree(root) } 堆堆通常是一个可以被看做一棵树的数组对象。堆的实现通过构造二叉堆（binary heap），实为二叉树的一种； 任意节点小于（或大于）它的所有后裔，最小元（或最大元）在堆的根上（堆序性）。 堆总是一棵完全树。即除了最底层，其他层的节点都被元素填满，且最底层尽可能地从左到右填入。将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。常见的堆有二叉堆、斐波那契堆等。 通常堆是通过一维数组来实现的。在数组起始位置为1的情形中： 父节点i的左子节点在位置 2 ×i ; 父节点i的右子节点在位置 2×i+1 ; 子节点i的父节点在位置 i÷2 ; LRU缓存机制package main import &quot;fmt&quot; type Node struct { pre *Node next *Node key int val int } type lruCache struct { cap int headNode *Node tailNode *Node nodeMap map[int]*Node } func (l *lruCache) get(k int) int { node := l.nodeMap[k] if node == nil { return -1 } headNode := l.headNode //将节点node的前驱结点和后继节点连接起来 node.pre.next = node.next node.next.pre = node.pre headNode.next.pre = node node.next = headNode.next headNode.next = node node.pre = headNode v := node.val return v } func (l *lruCache) set(k, v int) { node := l.nodeMap[k] if node == nil { if len(l.nodeMap) == l.cap { lastNode := l.tailNode.pre lastNode.pre.next = l.tailNode l.tailNode.pre = lastNode.pre lastNode.pre = nil lastNode.next = nil deleteKey := lastNode.key delete(l.nodeMap, deleteKey) } newNode := &amp;Node{ pre: l.headNode, next: l.headNode.next, key: k, val: v, } l.headNode.next = newNode l.headNode.next.pre = newNode l.nodeMap[k] = newNode } else { node.val = v //摘除node node.pre.next = node.next node.next.pre = node.pre l.headNode.next.pre = node l.headNode.next = node node.pre = l.headNode node.next = l.headNode.next } } func main() { head := &amp;Node{ pre: nil, next: nil, key: 0, val: 0, } tail := &amp;Node{ pre: nil, next: nil, key: 0, val: 0, } head.next = tail tail.pre = head lru := lruCache{ cap: 2, headNode: head, tailNode: tail, nodeMap: make(map[int]*Node), } lru.set(1, 1) lru.set(2, 2) re := lru.get(1) fmt.Println(re) // 1 lru.set(3, 3) re = lru.get(2) fmt.Println(re) // -1 re = lru.get(3) fmt.Println(re) // 3 lru.set(4, 4) re = lru.get(1) fmt.Println(re) // -1 re = lru.get(3) fmt.Println(re) // 3 re = lru.get(4) fmt.Println(re) // 4 } 经典链表https://www.cnblogs.com/huangliang-hb/p/10855558.html","tags":[]},{"title":"","date":"2022-02-27T11:55:12.000Z","path":"2022/02/27/kafka/","text":"KafkaTopic和PartitionTopic在 kafka 中，topic 是一个存储消息的逻辑概念，可以认为是一个消息集合。每条消息发送到 kafka 集群的消息都有一个类别。物理上来说，不同的 topic 的消息是分开存储的，每个 topic 可以有多个生产者向它发送消息，也可以有多个消费者去消费其中的消息。 Partition：每个 topic 可以划分多个分区（每个 Topic 至少有一个分区），同一 topic 下的不同分区包含的消息是不同的。每个消息在被添加到分区时，都会被分配一个 offset（称之为偏移量），它是消息在此分区中的唯一编号，kafka 通过 offset保证消息在分区内的顺序，offset 的顺序不跨分区，即 kafka只保证在同一个分区内的消息是有序的。下图中，对于名字为 test 的 topic，做了 3 个分区，分别是p0、p1、p2. ➢ 每一条消息发送到 broker 时，会根据 partition 的规则选择存储到哪一个 partition。如果 partition 规则设置合理，那么所有的消息会均匀的分布在不同的partition中，这样就有点类似数据库的分库分表的概念，把数据做了分片处理。 kafka 消息分发策略： 消息是 kafka 中最基本的数据单元，在 kafka 中，一条消息由 key、value 两部分构成，在发送一条消息时，我们可以指定这个 key，那么 producer 会根据 key 和 partition 机制来判断当前这条消息应该发送并存储到哪个 partition 中。我们可以根据需要进行扩展 producer 的 partition 机制 消息默认的分发机制： 默认情况下，kafka 采用的是 hash 取模的分区算法。如果Key 为 null，则会随机分配一个分区。这个随机是在这个参数”metadata.max.age.ms”的时间范围内随机选择一个。对于这个时间段内，如果 key 为 null，则只会发送到唯一的分区。这个值在默认情况下是 10 分钟更新一次。关 于 Metadata ，简单理解就是Topic/Partition 和 broker 的映射关系，每一个 topic 的每一个 partition，需要知道对应的 broker 列表是什么，leader是谁、follower 是谁。这些信息都是存储在 Metadata 这个类里面。 谁来执行 Rebalance 以及管理 consumer 的 group 呢？Kafka 提供了一个角色：coordinator(协调员) 来执行对于 consumer group 的管理，当 consumer group 的第一个 consumer 启动的时候，它会去和 kafka server(broker) 确定谁是它们组的 coordinator。之后该 group 内的所有成员都会和该 coordinator 进行协调通信。consumer group 如何确定自己的 coordinator 是谁呢？ 消费 者 向 kafka 集 群 中 的 任 意 一 个 broker 发 送 一 个GroupCoordinatorRequest 请求，服务端会返回一个负载最小的 broker 节 点 的 id ， 并 将 该 broker 设 置 为coordinator。在 rebalance 之前，需要保证 coordinator 是已经确定好了的，整个 rebalance 的过程分为两个步骤 ，一个是JoinGroup 的过程，在这个过程之后会进入一个Synchronizing Group State 阶段。那么这两个阶段都做了什么呢？ JoinGroup 的过程： 表示加入到 consumer group 中，在这一步中，所有的成员都会向 coordinator 发送 joinGroup 的请求。一旦所有成员都发送了 joinGroup 请求，那么 coordinator 会选择一个 consumer 担任 leader 角色，并把组成员信息和订阅信息发送消费者。下图就是描述了这么一个过程，并且请求与响应中携带的一些重要的信息。 protocol_metadata: 序列化后的消费者的订阅信息 leader_id： 消费组中的消费者，coordinator 会选择一个座位 leader，对应的就是 member_id member_metadata 对应消费者的订阅信息 members：consumer group 中全部的消费者的订阅信息 generation_id：年代信息，类似于 zookeeper 的时候的 epoch 是一样的，对于每一轮 rebalance ，generation_id 都会递增。主要用来保护 consumer group。隔离无效的 offset 提交。也就是上一轮的consumer 成员无法提交 offset 到新的 consumer group 中。 Synchronizing Group State 阶段：进入了 Synchronizing Group State阶段，主要逻辑是向 GroupCoordinator 发 送SyncGroupRequest 请求，并且处理 SyncGroupResponse响应，简单来说，就是 leader 将消费者对应的 partition 分配方案同步给 consumer group 中的所有 consumer，每个消费者都会向 coordinator 发送 syncgroup 请求，不过只有 leader 节点会发送分配方案，其他消费者只是打打酱油而已。当 leader 把方案发给 coordinator 以后，coordinator 会把结果设置到 SyncGroupResponse 中。这样所有成员都知道自己应该消费哪个分区。 消息的存储：首先我们需要了解的是，kafka 是使用日志文件的方式来保存生产者和发送者的消息，每条消息都有一个 offset 值来表示它在分区中的偏移量。Kafka 中存储的一般都是海量的消息数据，为了避免日志文件过大，Log 并不是直接对应在一个磁盘上的日志文件，而是对应磁盘上的一个目录，这个目录的命名规则是_比如创建一个名为 firstTopic 的 topic，其中有 3 个 partition，那么在 kafka 的数据目录（/tmp/kafka-log，这里可以通过server.properties中的log.dirs=/tmp/kafka-logs去修改）中就有 3 个目录，firstTopic-0~3多个分区在集群中的分配 如果我们对于一个 topic，在集群中创建多个 partition，那么 partition 是如何分布的呢？ 1.将所有 N Broker 和待分配的 i 个 Partition 排序2.将第 i 个 Partition 分配到第(i mod n)个 Broker 上 幂等性: 所谓的幂等，简单说就是对接口的多次调用所产生的结果和调用一次是一致的。在0.11.0.0版本引入了创建幂等性Producer的功能。仅需要设置props.put(“enable.idempotence”，true)，或props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG,true)。enable.idempotence设置成true后，Producer自动升级成幂等性Producer。Kafka会自动去重。Broker会多保存一些字段。当Producer发送了相同字段值的消息后，Broker能够自动知晓这些消息已经重复了。作用范围： 只能保证单分区上的幂等性，即一个幂等性Producer能够保证某个主题的一个分区上不出现重复消息。只能实现单回话上的幂等性，这里的会话指的是Producer进程的一次运行。当重启了Producer进程之后，幂等性不保证。","tags":[]},{"title":"如何发现代码的坏味道之SLAP原则","date":"2019-03-22T06:28:42.000Z","path":"2019/03/22/设计模式/单一抽象层级原则-SLAP/","text":"Long Method (代码的坏味道) 可读性很差 复用性差 难以调试 难以维护 冗余代码多 SLAP(单一抽象原则)定义SLAP 是 Single Level of Abstraction 的缩写。解释：指定代码块上的代码应该在单一的抽象层上。 SLAP优势 短方法的提取产生，会使得方法更加具有原子性，职责更加单一，更加的符合Unix的哲学 Do one thing, and do it well。 短方法的复用性更强，使得编码更加便捷 短方法可读性更强，更加便于理解 实践表明，SLAP应用后，维护成本应该是降低的。 举例&lt;?php class User { public static function getUserInfo() { return [ &#39;email&#39; =&gt; &#39;786188095@qq.com&#39;, &#39;password&#39; =&gt; &#39;232321312312&#39; ]; } } function validateUser($user_info) { $preg_email=&#39;/^[a-zA-Z0-9]+([-_.][a-zA-Z0-9]+)*@([a-zA-Z0-9]+[-.])+([a-z]{2,5})$/ims&#39;; if (!preg_match($preg_email,$user_info[&#39;email&#39;])) { return false; } if (strlen($user_info[&#39;password&#39;]) &lt;= 6) { return false; } //验证用户名 不包含特殊符号 //验证银行卡号 //验证银行卡开户行信息 //以此类推 方法越来越长 } validateUser(User::getUserInfo()); 代码存在的问题 validateUser 方法中暴露了校验email和密码的具体实现 validateUser 方法应该只关心校验结果（第一层抽象），而不是具体实现（第二层抽象） validateUser 违反了SLAP原则 修改后 &lt;?php class User { public static function getUserInfo() { return [ &#39;email&#39; =&gt; &#39;786188095@qq.com&#39;, &#39;password&#39; =&gt; &#39;232321312312&#39; ]; } } class UserValidator { protected static $preg_email = &#39;/^[a-zA-Z0-9]+([-_.][a-zA-Z0-9]+)*@([a-zA-Z0-9]+[-.])+([a-z]{2,5})$/ims&#39;; public static function validateEmail($email) { if (!preg_match(self::$preg_email,$email)) { return false; } return true; } public static function validatePassWord($password) { if (strlen($password) &lt;= 6) { return false; } return true; } } function vailUserInfo($user_info) { return UserValidator::validateEmail($user_info[&#39;email&#39;]) &amp;&amp; UserValidator::validatePassWord($user_info[&#39;password&#39;]); } var_dump(vailUserInfo(User::getUserInfo()));","tags":[]},{"title":"Linux IO模型","date":"2019-03-22T02:26:05.000Z","path":"2019/03/22/网络基础/Linux IO模型/","text":"#概念说明 用户空间和内核空间 进程切换 进程堵塞 文件描述符 缓存IO 用户空间和内核空间操作系统的核心是内核，独立于普通应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保存内核的安全，操作系统将虚拟空间划分为两部分，一部分是内核空间，一部分为用户空间。 进程切换为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。 进程堵塞正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。 文件描述符fd文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念 缓存IO缓存IO又被称作标准IO，大部分文件系统默认的IO操作都是缓存IO。数据会被先拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。 Linux IO模型网络IO的本质是socket的读取，socket在linux系统被抽象为流，IO可以理解为对流的操作。常见的IO模型有阻塞、非阻塞、IO多路复用，异步 同步阻塞IO同步阻塞 IO 模型是最常用的一个模型，也是最简单的模型。在linux中，默认情况下所有的socket都是blocking。它符合人们最常见的思考逻辑。阻塞就是进程 “被” 休息, CPU处理其它进程去了。 同步非堵塞IO同步非阻塞就是 “每隔一会儿瞄一眼进度条” 的轮询（polling）方式。 对比同步阻塞IO优点：能够在等待任务完成的时间里干其他活了（包括提交其他任务，也就是 “后台” 可以有多个任务在同时执行）。缺点：任务完成的响应延迟增大了，因为每过一段时间才去轮询一次read操作，而任务可能在两次轮询之间的任意时间完成。这会导致整体数据吞吐量的降低。 IO多路复用IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。当需要同时处理多个客户端接入请求时，可以利用多线程或者IO多路复用技术进行处理。IO多路复用的最大优势就是系统开销小，系统不需要额外创建进程或者线程，也不需要维护这些进程和线程的运行，降底了系统的维护工作量，节省了系统资源。 异步非阻塞 IO相对于同步IO，异步IO不是顺序执行。用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。IO两个阶段，进程都是非阻塞的","tags":[]},{"title":"浅谈微服务架构","date":"2019-03-21T07:43:22.000Z","path":"2019/03/21/微服务/浅谈微服务架构/","text":"微服务组成部分 服务描述 注册中心 服务框架 服务监控 服务追踪 服务治理 ###服务描述常见的服务描述方式包括RESTful API、XML配置以及IDL文件三种。 RESTful API方式通常用于HTTP协议的服务描述 XML配置方式多用作RPC协议的服务描述，通过*.xml配置文件来定义接口名、参数以及返回值类型等。 IDL文件方式通常用作Thrift和gRPC这类跨语言服务调用框架 注册中心服务提供者将自己提供的服务以及地址登记到注册中心，服务消费者则从注册中心查询所需要调用的服务的地址，然后发起请求。 工作流程 服务提供者在启动时，根据服务发布文件中配置的发布信息向注册中心注册自己的服务。 服务消费者在启动时，根据消费者配置文件中配置的服务信息向注册中心订阅自己所需要的服务。 注册中心返回服务提供者地址列表给服务消费者。 当服务提供者发生变化，比如有节点新增或者销毁，注册中心将变更通知给服务消费者。 服务框架服务消费者从注册中心获取服务提供者的地址，有了地址就可以发起调用。 服务通信采用协议的选择？ TCP、UDP or HTTP协议 数据传输采用方式？ 同步 or 异步 单连接传输 or 多路复用","tags":[]},{"title":"什么是单体应用","date":"2019-03-12T08:37:33.000Z","path":"2019/03/12/微服务/什么是单体应用/","text":"概念什么是单体应用一个归档包包含所有功能的应用程序，比如一些LAMP（Linux+Apache+MySQL+PHP）+和MVC（Spring + iBatis/Hibernate + Tomcat）两大流派。 单体应用架构图###单体应用出现的问题 部署效率低下：单体应用代码和依赖的资源越来越多，应用打包和部署测试，耗时久。 团队协作开发成本高： 系统高可用差 服务化拆分的两种姿势 纵向拆分，是从业务维度进行拆分。标准是按照业务的关联程度来决定，关联比较密切的业务适合拆分为一个微服务，而功能相对比较独立的业务适合单独拆分为一个微服务。 横向拆分，是从公共且独立功能维度拆分。标准是按照是否有公共的被多个其他服务调用，且依赖的资源独立不与其他业务耦合。 服务化拆分的前置条件 服务如何定义？对于单体应用来说，不同功能模块之前相互交互时，通常是以类库的方式来提供各个模块的功能。对于微服务来说，每个服务都运行在各自的进程之中，应该以何种形式向外界传达自己的信息呢？答案就是接口，无论采用哪种通讯协议，是HTTP还是RPC，服务之间的调用都通过接口描述来约定，约定内容包括接口名、接口参数以及接口返回值 服务如何发布和订阅单体应用由于部署在同一个WAR包里，接口之间的调用属于进程内的调用。而拆分为微服务独立部署后，服务提供者该如何对外暴露自己的地址，服务调用者该如何查询所需要调用的服务的地址呢？这个时候你就需要一个类似登记处的地方，能够记录每个服务提供者的地址以供服务调用者查询，在微服务架构里，这个地方就是注册中心。 服务如何监控通常对于一个服务，我们最关心的是QPS（调用量）、AvgTime（平均耗时）以及P999（99.9%的请求性能在多少毫秒以内）这些指标。这时候你就需要一种通用的监控方案，能够覆盖业务埋点、数据收集、数据处理，最后到数据展示的全链路功能。 服务如何治理可以想象，拆分为微服务架构后，服务的数量变多了，依赖关系也变复杂了。比如一个服务的性能有问题时，依赖的服务都势必会受到影响。可以设定一个调用性能阈值，如果一段时间内一直超过这个值，那么依赖服务的调用可以直接返回，这就是熔断，也是服务治理最常用的手段之一。 故障如何定位在单体应用拆分为微服务之后，一次用户调用可能依赖多个服务，每个服务又部署在不同的节点上，如果用户调用出现问题，你需要有一种解决方案能够将一次用户请求进行标记，并在多个依赖的服务系统中继续传递，以便串联所有路径，从而进行故障定位。","tags":[]},{"title":"委托模式","date":"2019-01-17T03:22:53.000Z","path":"2019/01/17/设计模式/委托模式/","text":"概念通过分配或委托至其他对象，委托模式能够去除核心对象中的判决和复杂的功能性。 实现场景添加音乐、并且根据音乐类型获取不同的音乐列表（返回字段形式均不一样） 使用委托模式 VS 基本实现 （UML） 使用基本实现方式调用时，需要if-else的判断，并且音乐类型不断增加，会导致PlayList类无限扩大。但是使用委托模式，在初始化类时，已经声明音乐类型$type,例如M3U，根据类型找到M3UPlaySong类，其余的查询列表均在委托类中进行实现。 代码实现&lt;?php class Playlist { private $_song; public function __construct() { $this-&gt;_song = []; } public function addSong($location, $title) { $song = [&#39;loc&#39;=&gt;$location,&#39;title&#39;=&gt;$title]; $this-&gt;_song[] = $song; } public function getM3UList() { $m3u = &quot;#M3U#\\n&quot;; foreach ($this-&gt;_song as $song) { $m3u .= &quot;音乐位置&quot;.$song[&#39;loc&#39;]; $m3u .= &quot;音乐名称&quot;.$song[&#39;title&#39;]; } return $m3u; } public function getPLSList() { $m3u = &quot;#PLS#\\n&quot;; foreach ($this-&gt;_song as $song) { $m3u .= &quot;music loc&quot;.$song[&#39;loc&#39;]; $m3u .= &quot;music title&quot;.$song[&#39;title&#39;]; } return $m3u; } } $obj = new Playlist(); $obj-&gt;addSong(&#39;ssss&#39;,&#39;every&#39;); $obj-&gt;addSong(&#39;dsdsda&#39;,&#39;one&#39;); $ext = &#39;m3u&#39;; if ($ext == &#39;m3u&#39;) { var_dump($obj-&gt;getM3UList()); } else { var_dump($obj-&gt;getPLSList()); } echo &quot;\\n&quot;; class NewPlaySong { private $_song; private $_SongType; public function __construct($type) { $this-&gt;_song =[]; $song_type = strtoupper($type).&#39;PlaySong&#39;; $this-&gt;_SongType = new $song_type (); } public function addSong($location, $title) { $song = [&#39;loc&#39;=&gt;$location,&#39;title&#39;=&gt;$title]; $this-&gt;_song[] = $song; } public function getPlayList() { $play_list = $this-&gt;_SongType-&gt;getPlayList($this-&gt;_song); return $play_list; } } class M3UPlaySong { public function getPlayList($song_list) { $m3u = &quot;#M3U#\\n&quot;; foreach ($song_list as $song) { $m3u .= &quot;音乐位置&quot;.$song[&#39;loc&#39;]; $m3u .= &quot;音乐名称&quot;.$song[&#39;title&#39;]; } return $m3u; } } $obj = new NewPlaySong(&#39;m3u&#39;); $obj-&gt;addSong(&#39;ssss&#39;,&#39;every&#39;); $obj-&gt;addSong(&#39;dsdsda&#39;,&#39;one&#39;); var_dump($obj-&gt;getPlayList());","tags":[{"name":"委托模式","slug":"委托模式","permalink":"http://blog.psonlyweb.cn/tags/委托模式/"}]},{"title":"适配器模式（Adapter Design Pattern）","date":"2019-01-10T09:00:45.000Z","path":"2019/01/10/设计模式/适配器模式/","text":"概念适配器设计模式只是将某个对象的接口适配为另一个对象所期望的接口。 UML图 ###代码实现 class errorObject { private $_error; public function __construct($error) { $this-&gt;_error = $error; } public function getError() { return $this-&gt;_error; } } class LogToCsvErrorObject extends errorObject{ private $error_num; private $error_msg; public function __construct($error) { parent::__construct($error); $error = $this-&gt;getError(); $parts = explode(&quot;:&quot;,$error); $this-&gt;error_num = $parts[0]; $this-&gt;error_msg = $parts[1]; } public function getErrorNum() { return $this-&gt;error_num; } public function getErrorMsg() { return $this-&gt;error_msg; } } class LogToConsole { private $_errorObject; public function __construct(errorObject $errorObject) { $this-&gt;_errorObject = $errorObject; } public function write() { fwrite(STDERR,$this-&gt;_errorObject-&gt;getError()); } } class LogToCSV { private $_errorObject; public function __construct(LogToCsvErrorObject $errorObject) { $this-&gt;_errorObject = $errorObject; } public function write() { $error_num = $this-&gt;_errorObject-&gt;getErrorNum(); $error_msg = $this-&gt;_errorObject-&gt;getErrorMsg(); fwrite(STDERR,$error_msg.&quot;错误码:&quot;.$error_num); } } $error_obj = new LogToCsvErrorObject(&quot;404:NOT FOUND&quot;); (new LogToCSV($error_obj))-&gt;write();","tags":[{"name":"适配器模式","slug":"适配器模式","permalink":"http://blog.psonlyweb.cn/tags/适配器模式/"}]},{"title":"快速排序","date":"2018-05-14T06:55:18.000Z","path":"2018/05/14/算法/快速排序/","text":"概念快速排序基于分治思想来实现。 分解：数组A[start,end]被划分为两个（可能为空）子数组A[start,postion-1]和A[postion+1,end]中的,使A[start,postion-1]的每一个元素都小于等于A[postion],A[postion+1,end]的每一个元素都大于等于A[postion]。 解决：通过递归调用快速排序，对子数组A[start,postion-1]和A[postion+1,end]进行排序。 合并：因为数组是原址排序，因此A[start,end]是有序的。 数组的划分（解决）实现思想图 PHP实现快速排序function quickSort(&amp;$array,$start,$end) { if ($start &lt; $end) { $postion = partition($array, $start, $end); quickSort($array,$start,$postion-1); quickSort($array,$postion+1,$end); } } function partition(&amp;$arr,$start,$end) { $flag = $arr[$end]; $i = $start-1; for ( $j=$start; $j&lt;= $end-1; $j++) { if($arr[$j] &lt;= $flag) { $i = $i+1; swap($arr,$i,$j); } } swap($arr,$i+1,$end); return $i+1; } function swap (&amp;$arr,$exist,$replace) { $temp = $arr[$exist]; $arr[$exist] = $arr[$replace]; $arr[$replace] = $temp; } $array = array(1,6,5,4); quickSort($array,0,3); var_dump($array);","tags":[{"name":"排序","slug":"排序","permalink":"http://blog.psonlyweb.cn/tags/排序/"}]},{"title":"优先队列(PriorityQueue)","date":"2018-05-08T03:53:16.000Z","path":"2018/05/08/算法/优先队列PriorityQueue/","text":"概述优先队列（priority queue）是一种用来维护由一组元素构成的集合S的数据结构，其中每一个元素都有一个相关的值，称为关键字（key）。队列的定义队列属于先进先出型，Frist in Frist out（FIFO）优先队列基于堆排序的方法进行实现的，堆排序每次都要进行建立最大堆，第一个元素为整个队列中的最大值，优先队列也是利用了堆排序这个性质达到优先队列中权值最大的先出的效果。 优先队列的方法 HeapMaximum方法实现了返回最大值 HeapExtractMax方法实现删除队列中的最大值并返回最大值 HeapIncreaseKey方法实现更改某个值。 MaxHeapInsert方法实现将元素插入到队列队尾 PHP实现优先队列 public function HeapMaximum($arr) { return $arr[0]; } public function HeapExtractMax(&amp;$arr,$length) { if($length &lt; 1) { return false; } $max = $arr[0]; $arr[0] = $arr[$length-1]; $length = $length - 1; $this-&gt;MaxHeapify($arr,1,$length); return $max; } public function HeapIncreaseKey(&amp;$arr,$i,$key) { if ($key &lt; $arr[$i]) { return false; } $arr[$i] = $key; $flag = $this-&gt;parent($i); while ($i &gt; 1 &amp;&amp; $arr[$flag] &lt; $arr[$i]) { $this-&gt;swap($arr,$flag,$i); $i = $this-&gt;parent($i); } } public function MaxHeapInsert(&amp;$arr,$key) { $length = count($arr) + 1; $arr[$length] = 0; $this-&gt;HeapIncreaseKey($arr,$length,$key); } 基于堆排序的PHP的部分代码class PriorityQueue { public function __construct(&amp;$arr) { $arr_length = count($arr)-1; $this-&gt;BuildMaxHeap($arr,$arr_length); } public function BuildMaxHeap(&amp;$arr,$arr_length) { $count = count($arr)-1; for ($i = floor($count/2); $i &gt;=0; $i--) { $this-&gt;MaxHeapify($arr,$i,$arr_length); } } public function MaxHeapify(&amp;$arr,$i,$arr_length) { $left = $this-&gt;left($i); $right = $this-&gt;right($i); if($left &lt;= $arr_length &amp;&amp; $arr[$left] &gt;= $arr[$i]) { $this-&gt;swap($arr,$i,$left); $largest = $left; } else { $largest = $i; } if ($right &lt;= $arr_length &amp;&amp; $arr[$right] &gt;= $arr[$largest]) { $this-&gt;swap($arr,$largest,$right); $largest = $right; } if ($largest != $i) { $this-&gt;MaxHeapify($arr,$largest); } } public function swap(&amp;$arr,$exist,$largest) { $temp = $arr[$exist]; $arr[$exist] = $arr[$largest]; $arr[$largest] = $temp; } private function left($i) { return 2*$i+1; } private function right($i) { return 2*$i+2; } private function parent($i) { return floor($i/2); } //以下是队列操作 }","tags":[{"name":"队列","slug":"队列","permalink":"http://blog.psonlyweb.cn/tags/队列/"}]},{"title":"网络分层TCP/IP","date":"2018-05-07T02:41:46.000Z","path":"2018/05/07/网络基础/网络分层TCP-IP/","text":"概述互联网分为五层，自下而上分为应用层、传输层、网络层、链接层、实体层。 实体层实体层就是把电脑连接在一起的物理手段。它主要规定了网络的一些电气特性，作用是负责传送0和1的电信号。 链接层拥有唯一的MAC地址进行标识，有了数据包和网卡MAC地址、广播的发送方式，链路层就可以在多台计算机之间传送数据。 网络层网络层关心的是如何把一个数据从一台设备发送到另一台设备。是主机到主机之间的通信。 传输层有了MAC地址和IP地址，我们可以在互联网任意两个主机上建立通信。区分一台主机中的接收的数据包属于哪个程序使用，是靠端口判断的。传输层的功能是从端口到端口的通信。因此Unix系统就把主机和端口叫作套接字(socket) UDP协议UDP数据包，也是由”标头”和”数据”两部分组成。“标头”部分主要定义了发出端口和接收端口，”数据”部分就是具体的内容。然后，把整个UDP数据包放入IP数据包的”数据”部分，而前面说过，IP数据包又是放在以太网数据包之中的，所以整个以太网数据包现在变成了下面这样： TCP协议UDP协议的优点是比较简单，容易实现，但是缺点是可靠性差，一旦数据发出后，无法知道对方是否收到。为了解决这个问题，TCP协议诞生。TCP协议可以理解为有确认机制的UDP协议。如果发送一个数据包遗失，就收不到确认，发送方就知道有必要重新发送数据包。而且TCP数据包没有长度限制，理论上可以无限长，但是为了保证网络效率通常TCP数据包的长度不会超过IP数据包长度，以保证单个TCP数据包不被分割。 应用层应用层的作用就是规定应用程序的数据格式。TCP协议可以为各种各样的程序传递数据，比如Email、WWW、FTP。必须有不同的协议规定电子邮件、网页、FTP数据格式，这些应用程序协议构成了“应用层”。","tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://blog.psonlyweb.cn/tags/TCP-IP/"}]},{"title":"堆排序","date":"2018-05-04T03:06:56.000Z","path":"2018/05/04/算法/堆排序/","text":"堆排序概念堆排序是利用堆这种数据结构而设计的一种排序算法。时间复杂度为O(nlogn)。 堆排序具有如下性质的完全二叉树:每个节点的值都大于或等于其左右孩子节点的值，称为最大堆；或每个节点都小于或者等于其左右孩子节点被称为最小堆。 对堆中的节点进行编号，将这种逻辑映射到数组中，如下： 堆排序的基本性质：最大堆：左右子节点小于父节点最小堆：左右子节点大于父节点 堆排序流程1.构建最大堆构建最大堆之前呈现效果如下： 构建最大堆之后呈现效果如下： 保证了堆排序中的最大堆的性质。2.堆排序算法实现取出构建最大堆中的最大值，放在尾部然后重新构建最大堆。 以此类推最终达到从小到大的排序效果，完成堆排序。 PHP实现堆排序&lt;?php /** * */ class HeapSort { public function __construct(&amp;$arr) { $arr_length = count($arr)-1; $this-&gt;HeapMaxSort($arr,$arr_length); } private function HeapMaxSort(&amp;$arr,$arr_length) {; $this-&gt;BuildMaxHeap($arr,$arr_length); for($i = $arr_length;$i &gt;= 0; $i--) { $this-&gt;swap($arr,$i,0); $arr_length--; $this-&gt;MaxHeapify($arr,0,$arr_length); } } private function BuildMaxHeap(&amp;$arr,$arr_length) { $count = count($arr)-1; for ($i = floor($count/2); $i &gt;=0; $i--) { $this-&gt;MaxHeapify($arr,$i,$arr_length); } } public function MaxHeapify(&amp;$arr,$i,$arr_length) { $left = $this-&gt;left($i); $right = $this-&gt;right($i); if($left &lt;= $arr_length &amp;&amp; $arr[$left] &gt;= $arr[$i]) { $this-&gt;swap($arr,$i,$left); $largest = $left; } else { $largest = $i; } if ($right &lt;= $arr_length &amp;&amp; $arr[$right] &gt;= $arr[$largest]) { $this-&gt;swap($arr,$largest,$right); $largest = $right; } if ($largest != $i) { $this-&gt;MaxHeapify($arr,$largest); } } public function swap(&amp;$arr,$exist,$largest) { $temp = $arr[$exist]; $arr[$exist] = $arr[$largest]; $arr[$largest] = $temp; } private function left($i) { return 2*$i+1; } private function right($i) { return 2*$i+2; } } $array = array(5,2,3,1,4,6); $Heap_Model = new HeapSort($array); var_dump($array);","tags":[{"name":"排序","slug":"排序","permalink":"http://blog.psonlyweb.cn/tags/排序/"}]},{"title":"最大子数组","date":"2018-04-26T09:47:41.000Z","path":"2018/04/26/算法/最大子数组/","text":"暴力求解最大子数组function violentMax($array,$count,&amp;$start,&amp;$end) { $sum = 0; $max = 0; for($i=0; $i &lt;= $count-1; $i++) { for ($j = $i; $j &lt;= $count-1 ; $j++) { $sum = 0; for($k = $i; $k &lt;= $j; $k++) { $sum += $array[$k]; } if ($sum &gt; $max) { $start = $i; $end = $j; $max = $sum; } } } return $max; } $array = array(3,-1,2,5,-3,4,-6,-7,1,8,-3,5,9); $count = count($array); $start = 0; $end = 0; $max = violentMax($array,$count,$start,$end); echo &#39;&lt;hr&gt;&#39;; echo $start; echo &#39;&lt;hr&gt;&#39;; echo $end; echo &#39;&lt;hr&gt;&#39;; echo $max; 上面方法的时间复杂度为O( n^2 ); 分治策略实现最大子数组&lt;?php class divideRule { public $left_pos; public $right_pos; public function divide($arr,$start,$end) { if ($start == $end) { return $arr[$start]; } else { $mid = floor(($start+$end)/2); $left_max = $this-&gt;divide($arr,$start,$mid); $right_max = $this-&gt;divide($arr,$mid+1,$end); $middle_max = $this-&gt;middleMax($arr,$start,$mid,$end); if ($left_max &gt;= $right_max &amp;&amp; $left_max &gt;= $middle_max) { return $left_max; } else if($right_max &gt;= $left_max &amp;&amp; $right_max &gt;= $middle_max) { return $right_max; } else { return $middle_max; } } } public function middleMax($arr,$start,$mid,$end) { $left_sum = 0; $sum = 0; for($i = $mid; $i &gt;= 0; $i--) { $sum = $sum + $arr[$i]; if ($sum &gt; $left_sum) { $left_sum = $sum; $this-&gt;left_pos = $i; } } $right_sum = 0; $sum = 0; for ($j = $mid+1; $j &lt;= $end ; $j++) { $sum = $sum + $arr[$j]; if ($sum &gt; $right_sum) { $right_sum = $sum; $this-&gt;right_pos = $j; } } $count_sum = $right_sum + $left_sum; return $count_sum; } } $array = array(3,-1,2,5,-3,4,-6,-7,1,8,-3,5,9); $count = count($array)-1; $rule_class = new divideRule(); $max = $rule_class-&gt;divide($array,0,$count); echo $rule_class-&gt;left_pos; echo $rule_class-&gt;right_pos; var_dump($max);","tags":[{"name":"最大子数组","slug":"最大子数组","permalink":"http://blog.psonlyweb.cn/tags/最大子数组/"}]},{"title":"归并排序","date":"2018-04-25T03:27:46.000Z","path":"2018/04/25/算法/归并排序/","text":"PHP实现归并排序算法&lt;?php function merger_sort(&amp;$arr,$frist,$end) { if($frist &lt; $end) { $middle = floor(($frist+$end)/2); merger_sort($arr,$frist,$middle); merger_sort($arr,$middle+1,$end); merger($arr,$frist,$middle,$end); } } function merger(&amp;$arr,$start,$mid,$end) { $i = $start; $j=$mid + 1; $k = $start; $temparr = array(); while($i!=$mid+1 &amp;&amp; $j!=$end+1) { if($arr[$i] &gt;= $arr[$j]){ $temparr[$k++] = $arr[$j++]; } else{ $temparr[$k++] = $arr[$i++]; } } while($i != $mid+1){ $temparr[$k++] = $arr[$i++]; } while($j != $end+1){ $temparr[$k++] = $arr[$j++]; } for($i=$start; $i&lt;=$end; $i++){ $arr[$i] = $temparr[$i]; } } function MergeSort(&amp;$arr){ $start = 0; $end = count($arr) - 1; merger_sort($arr,$start,$end); } $array = array(5,2,7,4); MergeSort($array); var_dump($array); 分治策略的步骤 分解 原问题为若干个子问题,这些子问题是原问题的规模较小的实例。 解决 这些子问题，递归地求解各子问题。然而子问题的规模足够小，则直接求解。 合并 这些子问题的解成原问题的解。 归并排序遵从分治策略 merger_sort函数完成了分解的步骤，将原数组array(5,2,7,4)最终分解为array(5,2)和array(7,4) merger函数完成了解决（排序）和合并的操作首先对分解的array(5,2)和array(7,4)进行排序，得到 array(2,5)和array(4,7),然后合并为array(2,5,4,7),然后继续merge进行解决，流程是将2与4进行比较拿出较小的放在原数组中，然后将4和5进行比较，然后比较5和7，完成归并排序。 总结归并排序的时间复杂度是o(nlogn)","tags":[{"name":"排序","slug":"排序","permalink":"http://blog.psonlyweb.cn/tags/排序/"}]},{"title":"Socket通信编程","date":"2018-02-01T09:41:21.000Z","path":"2018/02/01/PHP/Socket通信编程/","text":"##Socket连接过程 服务器监听：服务端套接字并不定位具体的客户端套接字，而是处于等待连接的状态，实时监控网络状态，等待客户端的连接请求。 客户端请求：指客户端的套接字提出连接请求，要连接的目标是服务器端的套接字。为此客户端的套接字必须首先描述它所要连接的服务器的套接字，并给出服务器端的套接字的地址和端口号，然后向服务器端提出连接请求。 连接确认：当服务器端套接字监听或者接收到客户端套接字的连接请求时，就响应客户端套接字的请求，建立一个新的线程，把服务器端的套接字的描述发给客户端，一旦客户端确认了此描述，双方就正式建立连接。而服务器端套接字继续处于监听状态，继续接受其他客户端套接字的连接请求。 PHP安全XSS防御 转义/编码 htmlspecialchars() 过滤 strip_tags CSP(Content Security Policy) 第三方库 HTML purifier htmLawed Zend_Filter_Input 会话攻击防御 session_regenerate_id() 二级令牌 检测UA和用户IP","tags":[]},{"title":"PHP异步并行","date":"2018-02-01T02:33:59.000Z","path":"2018/02/01/PHP/PHP异步并行/","text":"一个PHP Web程序的执行过程 请求开始 (GET/Post/Cookie/Session) Mysql数据库查询/Redis查询 模板渲染输出HTML/json_encode 请求结束(回收所有内存和资源) PHP-FPM进程的完整流程 请求1 处理请求 发送响应 请求2 处理请求 发送响应 请求3 处理请求 发送响应 。。。。 Accept-&gt;Recv(处理)-&gt;Send-&gt;Close-&gt;Accept-&gt;Recv-&gt;Send-&gt;Close 多进程并发地处理请求 进程1 请求1-&gt;请求2-&gt;……-&gt;请求N 进程2 进程3 … 进程N 扩展 stream sockets libevent/event pcntl/posix pthread sysvsem/sysvmsg shmop/sysvshm PHP同步阻塞$serv = stream_socket_server(&quot;tcp://0.0.0.0:8000&quot;,$errno,$errstr) or die (&quot;服务创建失败&quot;); for ($i=0; $i&lt;32 ;$i++) { if (pcntl_fork() == 0) { while(1) { $conn = stream_socket_accept($serv); $request = fread($conn); $response = &quot;Hello 异步并行&quot;; fwrite($response); fclose($conn); } exit(0); } }","tags":[]},{"title":"Vagrant使用","date":"2018-01-26T08:50:16.000Z","path":"2018/01/26/Vagrant/","text":"Vagrant常用命令 vagrant box list 查看目前已有的box vagrant box add 新增一个box vagrant box remove 删除指定的box vagrant init 初始化配置vagrantfile vagrant up 启动虚拟机 vagrant ssh ssh登录虚拟机 vagrant suspend 挂起虚拟机 vagrant reload 重启虚拟机 vagrant half 关闭虚拟机 vagrant status 查看虚拟机状态 vagrant destroy 删除虚拟机 对虚拟机的优化 替换源 sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak #备份源文件 sudo vim /etc/apt/source.list #修改源 sudo apt-get update #更新列表 源内容如下： deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse 安装Apache Nginx PHPsudo apt-get install 对应名称对应名称 -v 可以查看版本号 Apache更改端口，将端口设置为8888 修改 ports.conf 文件 curl -I ‘http://127.0.0.1:8888‘ Mysql 安装 sudo apt-get install mysql-server #服务器端 安装期间会提示输入为mysql设置root密码，我这边不操作，直接enter 不设置密码 sudo apt-get install mysql-client #客户端 mysql -uroot -p #测试连接库，上面安装服务端没有设置密码，这里直接enter进入 php扩展 sudo apt-get install 名称 php5-mcrypt php5-mysql php5-gd 支持apache2的php sudo apt-get install libapache2-mod-php5 开启rewrite功能 sudo a2enmod rewrite支持nginx fastcgi sudo apt-get install php5-cgi php5-fpm 修改成9000端口 ，默认sock模式 cd /etc/php5/fpm/pool.d sudo vim www.conf # search listen = 127.0.0.1:9000 sudo /etc/init.d/php5-fpm restart ##Vagrant高级知识 端口转发 config.vm.network &quot;forwarded_port&quot;, guest: 8888, host: 8889 共享文件夹config.vm.synced_folder &quot;/Users/ps/www&quot;,&quot;/home/www&quot;,:nfs=&gt;true 私有网络设置 config.vm.network &quot;private_network&quot;, ip: &quot;192.168.33.10&quot; 虚拟机优化 虚拟机名称 vb.name = &quot;ubuntu_ps&quot; 虚拟机主机名 config.vm.hostname = &quot;ps&quot; 配置虚拟机内存和CPU vb.memory = &quot;1024&quot; vb.cpus = 2 打包分发1.打包vagrant package –output xxx.boxvagrant package –output xxx.box –base 虚拟机名称","tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.psonlyweb.cn/tags/Linux/"}]},{"title":"设计模式之装饰器模式","date":"2018-01-02T03:07:36.000Z","path":"2018/01/02/设计模式/设计模式之装饰器模式/","text":"文章类获取初始的文章内容 class Art { protected $content = null; public function __construct($content) { $this-&gt;content = $content; } public function decorator() { return $this-&gt;content; } } 定义装饰文章类art 参数 保存着 文章类的初始化对象 class ArtDesc extends Art { protected $art = null; public function __construct($art) { $this-&gt;art = $art; } public function decorator() { } } SEO类和AD类继承装饰器类达到对文章内容的添加的效果 class SeoArt extends ArtDesc { public function decorator() { return $this-&gt;art-&gt;decorator().&#39;SEO KEYWORDS&#39;; } } class AdArt extends ArtDesc { public function decorator() { return $this-&gt;art-&gt;decorator().&#39;广告内容&#39;; } } 调用将初始化文章基础对象 传入装饰器类 $art = new Art(&#39;文章内容&#39;); $art = new SeoArt($art); $art = new AdArt($art); echo $art-&gt;decorator();","tags":[{"name":"PHP","slug":"PHP","permalink":"http://blog.psonlyweb.cn/tags/PHP/"},{"name":"设计模式","slug":"设计模式","permalink":"http://blog.psonlyweb.cn/tags/设计模式/"}]},{"title":"设计模式之策略模式","date":"2018-01-02T02:01:34.000Z","path":"2018/01/02/设计模式/设计模式之策略模式/","text":"设计模式之策略模式 面向对象中有什么比是什么更灵活 组合比继承更灵活 饭店和厨师的关系 是 一对多 比如新开饭店 如果单纯的复制饭店 这样不能会造成很多浪费的方法 但是如果以饭店拥有厨师的方式处理 那么 饭店的样式可以随机变换，因此首先声明一个饭店类 class FD { protected $tangCreator = null; protected $caiCreator = null; protected $fanCreator = null; public function __construct($f,$c,$t) { $this-&gt;fanCreator = $f; $this-&gt;tangCreator = $t; $this-&gt;caiCreator = $c; } public function createFan() { return $this-&gt;fanCreator-&gt;fan(); } public function createCai() { return $this-&gt;caiCreator-&gt;cai(); } public function createTang() { return $this-&gt;tangCreator-&gt;tang(); } } 再声明厨师类 class SouthDinner { public function fan() { return &#39;米饭&#39;; } public function cai() { return &#39;甜食&#39;; } public function tang() { return &#39;蛋花汤&#39;; } } class NorthDinner { public function fan() { return &#39;馒头&#39;; } public function cai() { return &#39;炒菜&#39;; } public function tang() { return &#39;粥&#39;; } } 最后调用 $fd = new FD(new SouthDinner(),new NorthDinner(),new SouthDinner()); echo $fd-&gt;createCai(),&#39;&lt;br&gt;&#39;; echo $fd-&gt;createTang(),&#39;&lt;br&gt;&#39;;","tags":[{"name":"PHP","slug":"PHP","permalink":"http://blog.psonlyweb.cn/tags/PHP/"},{"name":"设计模式","slug":"设计模式","permalink":"http://blog.psonlyweb.cn/tags/设计模式/"}]},{"title":"“设计模式之责任链”","date":"2017-12-29T02:46:16.000Z","path":"2017/12/29/设计模式/设计模式之责任链/","text":"设计模式之责任链 定义子类首先定义三个类，要声明power权值,以power来判断是否有权利去操作，传过来的数据，还需要声明上一级，责任链模式，要有层级关系 class Banzhu extends Admin { protected $power = 1; protected $top = &#39;Police&#39;; public function doProc() { echo &#39;删帖&#39;; } } class Police extends Admin { protected $power = 2; protected $top = &#39;Guoan&#39;; public function doProc() { echo &#39;抓人&#39;; } } class Guoan extends Admin { protected $power = 3; protected $top = null; public function doProc() { echo &#39;灭口&#39;; } } 定义父类子类均要继承父类方法Admin,Admin的__construct构造方法中，首先判断该类的上一级是否为空,如果是，那么该类是这个责任链中的顶级。 class Admin { public function __construct() { if ($this-&gt;top == null) { return; } $this-&gt;toper = new $this-&gt;top(); } public function proc($danger) { if($danger &lt;= $this-&gt;power) { $this-&gt;doProc(); } else { $this-&gt;toper-&gt;proc($danger); } } } 调用实例化最底层类，然后调用方法传入power $obj = new Banzhu(); $obj-&gt;proc(3);","tags":[{"name":"PHP","slug":"PHP","permalink":"http://blog.psonlyweb.cn/tags/PHP/"},{"name":"设计模式","slug":"设计模式","permalink":"http://blog.psonlyweb.cn/tags/设计模式/"}]},{"title":"“设计模式之工厂模式 抽象工厂”","date":"2017-12-26T07:59:38.000Z","path":"2017/12/26/设计模式/设计模式之工厂模式 抽象工厂/","text":"设计模式之工厂模式 抽象工厂多个类具有相同的属性和方法 1.首先声明类 class Mysql { } class Sqlite { } class MyPdo { } 2.建立一个工厂类接口，工厂类中可以声明属性和方法 interface Factory { public static function getDB(); } 3.然后声明抽象工厂类 实现工厂类接口中的静态方法 class MysqlFactory implements Factory { public static function getDB() { return new Mysql(); } } class MyPdoFactory implements Factory { public static function getDB() { // TODO: Implement getDB() method. return new MyPdo(); } } class MysqlliteFactory implements Factory { public static function getDB() { // TODO: Implement getDB() method. return new Sqlite(); } } 4、最后调用工厂类中的静态方法 $factory = &#39;MysqlFactory&#39;; $db = $factory::getDB(); print_r($db);","tags":[{"name":"抽象工厂","slug":"抽象工厂","permalink":"http://blog.psonlyweb.cn/tags/抽象工厂/"}]},{"title":"“JS设计模式之观察者模式”","date":"2017-12-26T07:58:16.000Z","path":"2017/12/26/设计模式/设计模式之观察者模式/","text":"设计模式之观察者模式 &lt;script&gt; var sel =document.getElementById(&#39;sel&#39;); sel.observes =[]; sel.attach =function (obj) { sel.observes[sel.observes.length] = obj; }; sel.detach = function (obj) { for( var i=0; i &lt; sel.observes.length; i++) { if(this.observes[i] == obj) { delete this.observes[i]; } } }; sel.onchange = sel.notify =function () { for( var i=0; i &lt; sel.observes.length; i++) { // this.observes[i].update(this); } }; var test2 = document.getElementById(&#39;test2&#39;); var test3 = document.getElementById(&#39;test3&#39;); test3.update = function (sel) { if(sel.value == &#39;1&#39;){ this.innerHTML = &#39;2&#39;; } else if(sel.value == &#39;0&#39;) { this.innerHTML =&#39;a&#39;; } }; test2.update = function (sel) { if(sel.value == &#39;1&#39;){ this.innerHTML = &#39;1&#39;; } else if(sel.value == &#39;0&#39;) { this.innerHTML =&#39;s&#39;; } }; sel.attach(test2); sel.attach(test3); &lt;/script&gt;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://blog.psonlyweb.cn/tags/设计模式/"},{"name":"JS","slug":"JS","permalink":"http://blog.psonlyweb.cn/tags/JS/"}]},{"title":"mysql主从复制","date":"2017-12-26T07:56:16.000Z","path":"2017/12/26/Mysql/mysql主从复制/","text":"mysql主从复制 一、 配置主服务器 编辑my.cnf文件 默认位置一般在/etc下 在[mysqld]的下面加入下面代码： log-bin=mysql-bin server-id=1 innodb_flush_log_at_trx_commit=1 sync_binlog=1 binlog-do-db=wordpress//表明备份哪个数据库 binlog_ignore_db=mysql //表明忽略mysql库的备份 2.重启mysql service mysqld restart 3.连接mysql数据库 mysql -u root -p 4.在主服务器上创建用户并赋予”REPLICATION SLAVE”权限 x.x.x.x为 从属服务器ip 已授权的方式创建用户 GRANT REPLICATION SLAVE -&gt; ON *.* -&gt; TO &#39;ps&#39;@&#39;192.168.199.118&#39; -&gt; IDENTIFIED BY &#39;123456&#39;; 5.执行以下命令锁定数据库以防止写入数据。 mysql&gt;FLUSH TABLES WITH READ LOCK; 6.导出数据库备份文件 mysqldump -u root -p --databases work --lock-tables=false &gt; all.sql //lock-tables 是否锁定数据表 //databases 数据库名 7.用scp命令传输数据库文件all.sql到从服务器 scp all.sql root@192.168.199.118:/root [注意:] scp命令使用时 主服务器和从服务器都要安装 openssh-clients yum install -y openssh-clients ssh -v //查看服务器上是否有openssh-clients 8.连接mysql数据库 进入mysql命令行查看master状态 mysql&gt; SHOW MASTER STATUS; +------------------+----------+--------------+------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | +------------------+----------+--------------+------------------+ | mysql-bin.000001 | 260 | work | mysql | +------------------+----------+--------------+------------------+ 9.解锁数据表 mysql&gt; UNLOCK TABLES; 二、 配置从属数据库 1.导入主数据库数据表 mysql -u root -p work &lt; all.sql [注释] &lt; 导入 &gt; 导出 2.编辑my.cnf,在[mysqld]下面加入 server-id=2 可以自己定义,保证唯一 3.登录mysql服务器，执行以下命令。 mysql&gt; CHANGE MASTER TO -&gt; MASTER_HOST=&#39;192.168.199.163&#39;, -&gt; MASTER_USER=&#39;ps&#39;, -&gt; MASTER_PASSWORD=&#39;123456&#39;, -&gt; MASTER_PORT=3306, -&gt; MASTER_LOG_FILE=&#39;mysql-bin.000001&#39;, -&gt; MASTER_LOG_POS=260, -&gt; MASTER_CONNECT_RETRY=10; [注意:] MASTER_HOST:主服务器的IP。 MASTER_HOST:主服务器的IP。 MASTER_USER：配置主服务器时建立的用户名 MASTER_PASSWORD：用户密码 MASTER_PORT：主服务器mysql端口，如果未曾修改，默认即可。 4.启动slave进程。 START SLAVE;//开启SLAVE进程 show slave status\\G //查看SLAVE进程状态 [注意]连接不上mysql数据库 有可能是防火墙的原因 service iptables stop","tags":[{"name":"主从复制","slug":"主从复制","permalink":"http://blog.psonlyweb.cn/tags/主从复制/"}]},{"title":"“单例模式”","date":"2017-12-26T07:53:42.000Z","path":"2017/12/26/设计模式/设计模式之单例模式/","text":"设计模式之单例模式 &lt;?php class Single { protected $rnd; protected static $ins =null ; //将自动加载 设置为 protected类型 //这样没法new 类名进行实例化 protected function __construct() { $this-&gt;rnd =rand(0,1000); } //声明一个静态方法 public static function getins(){ //判断self::$ins 保存着实例化之后的对象 if (self::$ins == null) { self::$ins = new self(); } return self::$ins; } } ?&gt;","tags":[{"name":"单例模式","slug":"单例模式","permalink":"http://blog.psonlyweb.cn/tags/单例模式/"},{"name":"PHP","slug":"PHP","permalink":"http://blog.psonlyweb.cn/tags/PHP/"}]},{"title":"编译安装PHP扩展","date":"2017-12-26T07:30:46.000Z","path":"2017/12/26/PHP/编译安装PHP扩展/","text":"编译安装PHP扩展1、下载PHP环境安装包 php-7.1.42、解压php安装包tar -zxf php-7.1.4.tar.gz3、进入ext和你要安装的扩展的目录4、执行phpize/usr/local/php7-bht/bin/phpize5、执行编译命令 ./configure --with-php-config=/usr/local/php7-bht/bin/php-config --with-curl=DIR ps: –with-curl 根据安装扩展不同更改 6、执行 make &amp;&amp; make install 7、然后会生成扩展名.so的文件目录在extensions下 /usr/local/php7-bht/lib/php/extensions/no-debug-non-zts-20160303/ 8、执行加载模块 /usr/local/php/bin/php -m |grep curl","tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.psonlyweb.cn/tags/Linux/"},{"name":"PHP扩展","slug":"PHP扩展","permalink":"http://blog.psonlyweb.cn/tags/PHP扩展/"}]},{"title":"“插入排序”","date":"2017-10-09T05:25:11.000Z","path":"2017/10/09/算法/插入排序/","text":"PHP实现插入排序算法&lt;?php function insert_sort($arr){ for ($i=1;$i&lt;count($arr);$i++){ $key=$arr[$i]; $j=$i-1; //插入排序判断条件 while($j&gt;=0 &amp;&amp; $arr[$j]&gt;$key){ $arr[$j+1]=$arr[$j]; $j=$j-1; } $arr[$j+1]=$key; } return $arr; } $arr= array(5,2,4,6,1,3); $arr=insert_sort($arr); var_dump($arr); ?&gt; 循环不变式（理解算法的正确性）循环不变式的三条性质： 初始化：循环的第一次迭代之前，它为真 保持：如果循环的某次迭代之前他为真，那么下一次迭代之前它仍为真。 终止：在循环终止时，不变式为我们提供一个有用的性质，该性质是用于证明算法是正确的。利用循环不变式证明插入排序是正确的 初始化:当$i=2时，进入循环，$i=2所在数组元素前只有一个A[1]，因为只有一个元素，那么这个判断之前，该数组一定是有序的。 保持:第二条性质，当第一次循环执行下来，A[1]与A[2]进行比较，A[1],A[2]按照由小到大进行排列，保持了初始化中的性质，循环到$i为任意值，那么循环过后1-j一定是有序的，保持数组是有序的性质。 终止：循环终止的条件是i &gt; 数组.length = n,因为每次循环i都会增加1，最终 1-n一定是有序排列的。总结插入一个数据之前，所在位置n之前的数据一定是有序排列的。 插入排序最坏运行时间为n² 最好的运行时间为n 那么该数组一定是有序的。","tags":[{"name":"排序","slug":"排序","permalink":"http://blog.psonlyweb.cn/tags/排序/"}]}]